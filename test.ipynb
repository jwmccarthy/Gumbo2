{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch.optim import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from gumbo.env.gym import TorchEnv\n",
    "from gumbo.data.buffer import EpisodicBuffer\n",
    "from gumbo.data.sampler import BatchSampler\n",
    "\n",
    "from gumbo.modules.core import MLP\n",
    "from gumbo.modules.encoder import IdentityEncoder, FlattenEncoder\n",
    "from gumbo.modules.policy import DiagonalGaussianPolicy, CategoricalPolicy\n",
    "from gumbo.modules.operator import ValueOperator\n",
    "\n",
    "from gumbo.data.collector import Collector\n",
    "\n",
    "from gumbo.optimizer import Optimizer\n",
    "\n",
    "from gumbo.learn import PPO\n",
    "from gumbo.learn import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "env = TorchEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = EpisodicBuffer.from_spec(env.env_spec, size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = CategoricalPolicy(\n",
    "    encoder=FlattenEncoder(),\n",
    "    body=MLP()\n",
    ").build(env.obs_spec, env.act_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = Collector(env, policy, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = ValueOperator(\n",
    "    encoder=FlattenEncoder(),\n",
    "    body=MLP()\n",
    ").build(env.obs_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = BatchSampler(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(policy, critic, sampler, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(collector, ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_ep_rew: -205.14696533339364, mean_ep_len: 97.52380952380952\n",
      "{'policy_loss': -0.012120097875595093, 'critic_loss': 841.9310913085938, 'entropy_loss': -0.0, 'approx_kl': -0.028607148677110672}\n",
      "mean_ep_rew: -135.62566028941762, mean_ep_len: 93.0909090909091\n",
      "{'policy_loss': -0.023400068283081055, 'critic_loss': 334.25970458984375, 'entropy_loss': -0.0, 'approx_kl': -0.02868829108774662}\n",
      "mean_ep_rew: -168.48262977600098, mean_ep_len: 93.0909090909091\n",
      "{'policy_loss': 0.04469699785113335, 'critic_loss': 189.08457946777344, 'entropy_loss': -0.0, 'approx_kl': -0.008667952381074429}\n",
      "mean_ep_rew: -149.51039106195623, mean_ep_len: 93.0909090909091\n",
      "{'policy_loss': -0.02336733788251877, 'critic_loss': 254.96791076660156, 'entropy_loss': -0.0, 'approx_kl': -0.016471894457936287}\n",
      "mean_ep_rew: -138.15854091644286, mean_ep_len: 102.4\n",
      "{'policy_loss': -0.027029041200876236, 'critic_loss': 242.38174438476562, 'entropy_loss': -0.0, 'approx_kl': -0.016380630433559418}\n",
      "mean_ep_rew: -85.69680507805036, mean_ep_len: 89.04347826086956\n",
      "{'policy_loss': -0.0011927001178264618, 'critic_loss': 100.23214721679688, 'entropy_loss': -0.0, 'approx_kl': -0.03035922721028328}\n",
      "mean_ep_rew: -89.23881978988648, mean_ep_len: 102.4\n",
      "{'policy_loss': -0.004715472459793091, 'critic_loss': 98.35302734375, 'entropy_loss': -0.0, 'approx_kl': -0.08417525142431259}\n",
      "mean_ep_rew: -106.94091182284885, mean_ep_len: 227.55555555555554\n",
      "{'policy_loss': -0.003932592459022999, 'critic_loss': 90.83385467529297, 'entropy_loss': -0.0, 'approx_kl': -0.011568667367100716}\n",
      "mean_ep_rew: -103.39212372723748, mean_ep_len: 120.47058823529412\n",
      "{'policy_loss': -0.018257293850183487, 'critic_loss': 143.65576171875, 'entropy_loss': -0.0, 'approx_kl': -0.0030171647667884827}\n",
      "mean_ep_rew: -102.01804481233869, mean_ep_len: 146.28571428571428\n",
      "{'policy_loss': 0.02136177569627762, 'critic_loss': 139.78858947753906, 'entropy_loss': -0.0, 'approx_kl': 0.009718568064272404}\n",
      "mean_ep_rew: -84.64208650588989, mean_ep_len: 170.66666666666666\n",
      "{'policy_loss': 0.005888853222131729, 'critic_loss': 83.8839340209961, 'entropy_loss': -0.0, 'approx_kl': -0.015663130208849907}\n",
      "mean_ep_rew: -99.39171579149034, mean_ep_len: 227.55555555555554\n",
      "{'policy_loss': -0.03170592710375786, 'critic_loss': 52.016571044921875, 'entropy_loss': -0.0, 'approx_kl': -0.01396274659782648}\n",
      "mean_ep_rew: -183.74026150173611, mean_ep_len: 227.55555555555554\n",
      "{'policy_loss': -0.0057580722495913506, 'critic_loss': 102.0763931274414, 'entropy_loss': -0.0, 'approx_kl': -0.0005701659247279167}\n",
      "mean_ep_rew: -190.60233688354492, mean_ep_len: 204.8\n",
      "{'policy_loss': -0.047918520867824554, 'critic_loss': 114.73649597167969, 'entropy_loss': -0.0, 'approx_kl': -0.021288976073265076}\n",
      "mean_ep_rew: -205.41253685951233, mean_ep_len: 256.0\n",
      "{'policy_loss': 0.0057656606659293175, 'critic_loss': 124.14582061767578, 'entropy_loss': -0.0, 'approx_kl': -0.036269646137952805}\n",
      "mean_ep_rew: -182.06687461005316, mean_ep_len: 227.55555555555554\n",
      "{'policy_loss': -0.021509595215320587, 'critic_loss': 79.7415542602539, 'entropy_loss': -0.0, 'approx_kl': -0.015281395986676216}\n",
      "mean_ep_rew: -228.32857840401786, mean_ep_len: 292.57142857142856\n",
      "{'policy_loss': 0.01524047926068306, 'critic_loss': 50.91609573364258, 'entropy_loss': -0.0, 'approx_kl': -0.02845749258995056}\n",
      "mean_ep_rew: -250.00802612304688, mean_ep_len: 256.0\n",
      "{'policy_loss': -0.04498368501663208, 'critic_loss': 45.216835021972656, 'entropy_loss': -0.0, 'approx_kl': -0.025573525577783585}\n",
      "mean_ep_rew: -243.63016637166342, mean_ep_len: 341.3333333333333\n",
      "{'policy_loss': -0.018386110663414, 'critic_loss': 67.38430786132812, 'entropy_loss': -0.0, 'approx_kl': 0.0023184772580862045}\n",
      "mean_ep_rew: -217.23693010542127, mean_ep_len: 227.55555555555554\n",
      "{'policy_loss': 0.005065571516752243, 'critic_loss': 36.062320709228516, 'entropy_loss': -0.0, 'approx_kl': 0.0022175172343850136}\n",
      "mean_ep_rew: -206.67296755313873, mean_ep_len: 256.0\n",
      "{'policy_loss': 0.02737283706665039, 'critic_loss': 37.77065658569336, 'entropy_loss': -0.0, 'approx_kl': 0.022650282829999924}\n",
      "mean_ep_rew: -248.6652463277181, mean_ep_len: 341.3333333333333\n",
      "{'policy_loss': -0.015233762562274933, 'critic_loss': 30.178871154785156, 'entropy_loss': -0.0, 'approx_kl': -0.015371342189610004}\n",
      "mean_ep_rew: -214.1964956919352, mean_ep_len: 341.3333333333333\n",
      "{'policy_loss': -0.0064444830641150475, 'critic_loss': 37.91927719116211, 'entropy_loss': -0.0, 'approx_kl': 0.0011151544749736786}\n",
      "mean_ep_rew: -189.2220126560756, mean_ep_len: 292.57142857142856\n",
      "{'policy_loss': -0.00838723499327898, 'critic_loss': 58.875404357910156, 'entropy_loss': -0.0, 'approx_kl': -0.033200137317180634}\n",
      "mean_ep_rew: -151.09892439842224, mean_ep_len: 256.0\n",
      "{'policy_loss': -0.035597868263721466, 'critic_loss': 31.555450439453125, 'entropy_loss': -0.0, 'approx_kl': -0.042482174932956696}\n",
      "mean_ep_rew: -212.4310144696917, mean_ep_len: 292.57142857142856\n",
      "{'policy_loss': -0.014899032190442085, 'critic_loss': 15.871886253356934, 'entropy_loss': -0.0, 'approx_kl': -0.008893202990293503}\n",
      "mean_ep_rew: -202.2303650379181, mean_ep_len: 409.6\n",
      "{'policy_loss': -0.04738127440214157, 'critic_loss': 115.37710571289062, 'entropy_loss': -0.0, 'approx_kl': -0.01151046808809042}\n",
      "mean_ep_rew: -197.25638580322266, mean_ep_len: 256.0\n",
      "{'policy_loss': -0.02431415393948555, 'critic_loss': 17.517210006713867, 'entropy_loss': -0.0, 'approx_kl': -0.0030825603753328323}\n",
      "mean_ep_rew: -146.6778223514557, mean_ep_len: 256.0\n",
      "{'policy_loss': 0.0002576489932835102, 'critic_loss': 35.75653839111328, 'entropy_loss': -0.0, 'approx_kl': 0.0004588216543197632}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m1000000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\Documents\\RL\\Gumbo2\\gumbo\\learn\\trainer.py:18\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, num_steps)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#self.logger.start(num_steps)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollector\u001b[38;5;241m.\u001b[39mcollect(num_steps):\n\u001b[1;32m---> 18\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39mupdate(data)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# log episode, update info\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# if self.logger:\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#     self.logger.log_episodic(data)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#     self.logger.log_training(info)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#     self.logger.set_progress(global_t)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     global_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\Documents\\RL\\Gumbo2\\gumbo\\learn\\ppo.py:90\u001b[0m, in \u001b[0;36mPPO.update\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39msample(data):\n\u001b[0;32m     89\u001b[0m     loss, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(b)\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mupdate(loss)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\Documents\\RL\\Gumbo2\\gumbo\\optimizer.py:29\u001b[0m, in \u001b[0;36mOptimizer.update\u001b[1;34m(self, loss)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm:\n\u001b[0;32m     27\u001b[0m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     adam(\n\u001b[0;32m    227\u001b[0m         params_with_grad,\n\u001b[0;32m    228\u001b[0m         grads,\n\u001b[0;32m    229\u001b[0m         exp_avgs,\n\u001b[0;32m    230\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    231\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    232\u001b[0m         state_steps,\n\u001b[0;32m    233\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    234\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    235\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    236\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    237\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    238\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    239\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    240\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    241\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    242\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    243\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    244\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    245\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    246\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m func(\n\u001b[0;32m    767\u001b[0m     params,\n\u001b[0;32m    768\u001b[0m     grads,\n\u001b[0;32m    769\u001b[0m     exp_avgs,\n\u001b[0;32m    770\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    771\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    772\u001b[0m     state_steps,\n\u001b[0;32m    773\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    774\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    775\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    776\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    777\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    778\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    779\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    780\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    781\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    782\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    783\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    784\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    785\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jwmcc\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:431\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    429\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    433\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
